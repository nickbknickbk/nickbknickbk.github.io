<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Responsible AI international community to reduce bias in AI music generation and analysis</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
	</head>
	<body id="top">

		<!-- Header -->
			<header id="header">
				<h0><strong>Music<br>RAI</strong></h0><br />
			</header>

		<!-- Main -->
			<div id="main">

				<!-- One -->
					<section id="one">
						<header class="major">
						
						<!--<h1>Duxianqin Workshop 2019</h1>-->
						</header>

						<h1>Ethical and Responsible AI Music Making Workshop 17 July 2024</h1>
						
						<p>As part of our <a href = "#projectinfo">MusicRAI</a> project we would like to invite you to take part in a one-day workshop on Responsible Music AI with a focus on bias in AI music generation systems. </p>

						<p>The event will be hosted on 17th July 2024 at the Creative Computing Institute, University of the Arts London, Holborn, London. There will be an opportunity to join parts of the workshop online. </p>

<h2>Workshop Overview </h2>

<p>Many AI Models depend on large datasets and so lack an equitable representation of musical diversity. The rising popularity of tools using such models leads to further marginalisation of musical styles for which big data sets simply do not exist or are very hard to source. </p>

<p>We will bring together an interdisciplinary community of musicians, academics, and stakeholders to collaboratively identify the potential and challenges for using low-resource models and small datasets in musical practice. </p>

<p>The workshop will consist of publicly streamed discussion panels, presentations of participants’ work, and brainstorming sessions on the future of AI and marginalised music. The event will be followed by an evening reception featuring live performances. </p>

<p>In the morning sessions we will focus on sharing and identifying current practices and challenges for AI music making with small datasets. The afternoon we will be dedicated to exploring opportunities and practical solutions to using small and marginalised datasets of music and other audio with AI. This will form the start of an international network and roadmap for a new ecosystem that we will build to rapidly open small music datasets and low-resource AI approaches to more wider use in music making and analysis. </p>

<h2>Registration </h2>
<p>Please register to the workshop through Eventbrite here: <a href = "https://www.eventbrite.co.uk/e/responsible-ai-and-music-workshop-tickets-927283629297">Register</a></p>

<p>We encourage you to present your music making practice and AI work at the workshop in a format of your choice (short presentation, demo, live performance). You will be able to indicate your willingness to present during registration. </p>

<h2>Provisional Agenda</h2>
<p>Please note that this is a provisional agenda subject to change. The final agenda will be confirmed closer to the workshop date.</p>

<table>
    <tbody>
        <tr>
            <td style="padding-left: 0; width: 25%;">
                <b>Weds 17th July 2024</b>
            </td>
            <td>

            </td>
        </tr>                    <tr>
            <td style="padding-left: 0; width: 25%;">
                <b>10:00 AM - 10:10 AM</b>
            </td>
            <td>
                <b style="font-size: 1.1em;">Opening Remarks</b>
            </td>
        </tr>
        <tr>
            <td style="padding-left: 0; width: 25%;"><b>10:10 AM - 10:40 AM</b></td>
            <td>
                <b style="font-size: 1.1em;">Case Study Presentations</b>
            </td>
        </tr>
        <tr>
            <td style="padding-left: 0; width: 25%;"><b>10:40 AM - 11:45 AM</b></td>
            <td>
                <b style="font-size: 1.1em;">Brainstorming and discussion summary</b>
                <div>Understanding features of marginalised music genres and datasets</div>
            </td>
        </tr>
        <tr>
            <td style="padding-left: 0; width: 25%;"><b>11:45 AM - 12:00 PM</b></td>
            <td>
                <b style="font-size: 1.1em;">Break</b>
            </td>
        </tr>
        <tr>
            <td style="padding-left: 0; width: 25%;"><b>12:00 PM - 13:00 PM</b></td>
            <td>
                <b style="font-size: 1.1em;">Panel Discussion (hybrid)</b>
                <div>Challenges and Opportunities for Music Creation</div><div style="padding-top: 0.5em;">Panelists:</div><ul style="list-style: none;margin-bottom: 0; padding-left:0;">
<li>François Pachet (Founder)</li>
<li>Rebecca Fiebrink (University of the Arts London)</li>
<li>Nuno Correia (Tallinn University)</li>
<li>Phoenix Perry (University of the Arts London)</li>
</ul><div style="padding-top: 0.5em;">Moderator:</div><ul style="list-style: none;margin-bottom: 0;padding-left:0;">
<li>Nick Bryan-Kinns (University of the Arts London)</li>



</ul>
            </td>
        </tr>
        <tr>
            <td style="padding-left: 0; width: 25%;"><b>1:00 PM - 2:00 PM</b></td>
            <td>
                <b style="font-size: 1.1em;">Lunch</b>
            </td>
        </tr>
        <tr>
            <td style="padding-left: 0; width: 25%;"><b>2:00 PM - 2:30 PM</b></td>
            <td>
                <b style="font-size: 1.1em;">Case Study Presentations</b>

            </td>
        </tr>
        <tr>
            <td style="padding-left: 0; width: 25%;"><b>2:30 PM - 3:45 PM</b></td>
            <td>
                <b style="font-size: 1.1em;">Brainstorming and discussion summary</b>
                <div>Identifying opportunities of small data approaches in music making</div>
            </td>
        </tr>
        <tr>
            <td style="padding-left: 0; width: 25%;"><b>3:45 PM - 4:00 PM</b></td>
            <td>
                <b style="font-size: 1.1em;">Break</b>
            </td>
        </tr>
        <tr>
            <td style="padding-left: 0; width: 25%;"><b>4:00 PM - 5:00 PM</b></td>
            <td>
                <b style="font-size: 1.1em;">Panel Discussion (hybrid)</b>
                <div>The Future of Music Creation</div><div style="padding-top: 0.5em;">Panelists:</div><ul style="list-style: none;margin-bottom: 0;padding-left:0;">
<li>Paul McCabe (Roland and AI For Music)</li>
<li>Hazel Savage (SoundCloud and Musiio)</li>
<li>Daisy Rosenblum (University of British Columbia)</li>
<li>CJ Carr (Dadabots)</li>
</ul><div style="padding-top: 0.5em;">Moderator:</div><ul style="list-style: none;margin-bottom: 0;padding-left:0;">
<li>Nick Bryan-Kinns (University of the Arts London)</li>



</ul>
            </td>
        </tr>
        <tr>
            <td style="padding-left: 0; width: 25%;">
            <div><b>5:00 PM - 8:00 PM</b></div>
            <div>5:30 PM - 7:30 PM</div>
            </td>
            <td>
                <b style="font-size: 1.1em;">Reception</b>
                <div style="padding-top: 0.5em;">Live performances:</div><ul style="list-style: none;margin-bottom: 0;padding-left:0;">
<li>digital selves</li>
<li>Portait XO</li>
<li>Dadabots</li>
<li>Gabriel Vigliensoni</li>

</ul>
            </td>
    </tr></tbody>
</table>


<h2>Contact Information </h2>

<p>For any inquiries or further information, please contact:<br>
	Anna Wszeborowska <a href = "a.wszeborowska@arts.ac.uk">a.wszeborowska@arts.ac.uk</a><br>
	Prof. Nick Bryan-Kinns <a href = "mailto:n.bryankinns@arts.ac.uk">n.bryankinns@arts.ac.uk</a></p>

<p>We look forward to your participation! </p>

<p>Funded by <a href = "https://www.rai.ac.uk">Responsible Artificial Intelligence (RAI) UK</a> <a href = "https://www.rai.ac.uk/international-partnerships">International Partnerships</a> (UKRI EPSRC grant reference EP/Y009800/1)</p>

<hr>

<a id="projectinfo"><h1>About the MusicRAI Research Project</h1></a>
						
						<p>This 12 month project <strong>"Responsible AI international community to reduce bias in AI music generation and analysis"</strong> will build an international community to address Responsible AI (RAI) challenges of bias in AI music generation and analysis.</p>
						<p>The aim of the project is to explore ways to tackle current over-reliance on huge training datasets for deep learning leads to AI models biased towards Western classical and pop music and marginalises other music genres. We will bring together an international and interdisciplinary team of researchers, musicians, and industry experts to make available AI tools, expertise, and datasets which improve access to marginalised music genres. This will directly benefit musicians and audiences engaging with a wider range of musical genres and benefits creative industries by offering new forms of music consumption.</p>

						<h2>Team</h2>
						<p>
							Lead: <b>Prof. Nick Bryan-Kinns</b> (University of the Arts London, UK; UAL)<br>
<b>Prof. Rebecca Fiebrink</b> (UAL) <br>
<b>Dr. Phoenix Perry</b> (UAL) <br>
<b>Anna Wszeborowska</b> (UAL) <br>
<b>Prof. Zijin Li</b> (Central Conservatory of Music, China; CCoM) <br>
<b>Dr. Nuno Correia</b> (Tallinn University, Estonia; TU) <br>
<b>Dr. Alex Lerch</b> (Georgia Tech, USA; GT) <br>
<b>Prof. Sid Fels</b> (University of British Columbia, Canada; UBC) <br>
<b>Dr. Gabriel Vigliensoni</b> (Concordia University, Canada; CU) <br>
<b>Dr. Andrei Coronel</b> and <b>Dr. Raphael Alampay</b> (Ateneo de Manila University, Philippines; AdMU) <br>
<b>Prof. Rikard Lindell</b> (Dalarna University, Sweden; DU)
						</p>

						<h2>Partners</h2>
						<p>
							<b>Music Hackspace</b> (UK)<br>
							<b>DAACI</b> (UK)<br>
							<b>Steinberg</b> (Germany)<br>
							<b>Bela</b> (UK)<br>
						</p>

						<h2>Objectives</h2>
							<ul>
							<li>To bring together and grow the international community of researchers, creative practitioners, and AI experts interested in using musical genres marginalised by current AI systems (AI marginalisation) as datasets for AI music making practice and research.</li>
							<li>To establish an open repository of marginalised musical genre datasets for use in AI.</li>
							<li>To bring together and make available methods and tools for how artists might use techniques such as low-resource deep learning models to generate music using marginalized music genres.</li>
							<li>To commission a small number of speculative artistic projects resulting in international showcase of generative AI music using marginalised musical genres.</li>
							<li>To explore the translational potential of the AI techniques identified in this project to other creative practices.</li>
						</ul>

<h2>Contact</h2>
<p>To get involved please contact Prof. Nick Bryan-Kinns <a href = "mailto:n.bryankinns@arts.ac.uk">n.bryankinns@arts.ac.uk</a></p>

						<h2>Funding</h2>

						<p>Funded by <a href = "https://www.rai.ac.uk">Responsible Artificial Intelligence (RAI) UK</a> <a href = "https://www.rai.ac.uk/international-partnerships">International Partnerships</a> (UKRI EPSRC grant reference EP/Y009800/1)</p>
						
														
					</section>
								
<hr>
					
				       <h6>Template: <a href="http://html5up.net/">HTML5 UP</a> </h6>

			</div>

		<!-- Footer -->
		
		<!--
			<footer id="footer">
				<ul class="icons">
					<li><a href="https://twitter.com/nickbknickbk" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
				</ul>
				
				<ul class="copyright">
                <h6><strong>Supported by:</strong><br /> <a href = "http://www.ccmusic.edu.cn">China Conservatory of Music</a><br /> <a href = "http://www.mat.qmul.ac.uk">EPSRC+AHRC Media and Arts Technology CDT</a><br /><a href = "http://qmul.ac.uk">Queen Mary University of London</a></h6> 

				</ul>
			</footer>
            -->    
		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>